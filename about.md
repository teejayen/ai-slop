---
layout: default
title: About This Project
permalink: /about/
---

# About This Project

## What This Is

This is a **research project studying AI-generated business content**. Every article on this site is created by Claude (Anthropic) using a multi-agent workflow, then transparently labelled and documented for analysis.

The goal: understand what differentiates substantive business analysis from generic "AI slop."

## Why This Exists

In early 2025, after years of evaluating AI business cases, a pattern became impossible to ignore: **AI-generated business content all sounds the same**. Every vendor deck, every thought leadership piece, every executive summary used identical phrases: "unlock value," "game-changing," "leverage AI to transform."

The question emerged: if AI-generated content follows predictable patterns, can we use AI itself to study those patterns? Can we teach AI systems to recognise and avoid their own worst tendencies?

## The Research Question

**What separates substantive business analysis from generic slop?**

- Can we quantify the difference?
- Can we identify specific markers of quality vs. mediocrity?
- Can AI systems learn to produce genuinely useful business content?
- What role does critical perspective play in avoiding generic output?

## How It Works

### Multi-Agent Content Generation

Articles are generated using Claude Code's orchestrator and review agent architecture:

1. **Research Phase**: Web search for current AI business trends, avoiding topics already covered
2. **Topic Selection**: Automatic selection based on Morgan Ashby's persona criteria (see [About the Author](/author/))
3. **Deep Research**: Focused queries gathering business implications, data, examples, critical perspectives
4. **Draft Generation**: Comprehensive 800-1200 word business-focused article
5. **Parallel Review**: Three specialist agents evaluate simultaneously:
   - **Business Focus Agent** (/10): Validates strategic value and business relevance
   - **Quality Standards Agent** (/10): Checks Australian English, readability, formatting
   - **Substance Agent** (/10): Detects generic patterns vs. substantive analysis
6. **Consolidation**: Apply critical fixes, integrate feedback
7. **Publication**: Save to Jekyll, commit to GitHub Pages with full review documentation

### Quality Thresholds

- Articles scoring **24+/30** are production-ready
- Below 24/30 requires iteration and fixes
- All scores published in [Research Documentation](/research/)

## Transparency Commitments

This project maintains rigorous transparency:

- **All content clearly labelled as AI-generated**
- **Multi-agent workflow fully documented** with source code available
- **Review scores published** alongside every article
- **Persona documentation accessible** (Morgan Ashby is a fictional research persona)
- **Research methodology open** for inspection and critique

## Why "AI Slop"?

The term "AI slop" refers to low-quality, generic AI-generated content that floods the internetâ€”articles that sound professional but say nothing substantive. This project embraces the term ironically:

- We're using AI to generate content
- We're studying what makes that content "slop" vs. substantive
- The repository name acknowledges the challenge directly

## Australian Focus

All content adheres to **Australian English** standards (optimise, realise, organise, centre) and incorporates Australian business context where relevant:

- ASX governance requirements
- Australian regulatory landscape
- Local tech ecosystem perspectives
- Sydney Tech Central insights

## The Irony Is Intentional

Yes, this is AI studying AI-generated content. The meta nature is the point. Can an AI system be taught to recognise its own patterns? Can it learn to avoid generic output? Can critical perspective be embedded in algorithmic processes?

We're finding out.

## What's Next

Current research goals (November 2025):

1. **Build a corpus** of 20-30 AI-generated business articles
2. **Document patterns** that emerge across the corpus
3. **Analyse review scores** to identify what works and what doesn't
4. **Refine workflows** based on findings
5. **Publish findings** about AI content quality markers

## Contact & Attribution

**Project:** AI Business Research (ai-slop)
**Location:** Sydney, Australia
**Powered by:** Claude Code (Anthropic)
**Research Lead:** Tim Neilen
**Persona/Voice:** Morgan Ashby (AI-generated)

**Repository:** [github.com/teejayen/ai-slop](https://github.com/teejayen/ai-slop)

---

*Last updated: November 2025*
